## LLaMA 2 from scratch 
- Including Rotary Positional Embedding, RMS Normalization, Multi Query Attention, KV Cache, Grouped Query Attention (GQA), the SwiGLU Activation function, ..


---

## LLaMA 2 Architecture
<p align="center">
  <img src="images\llama_arc.png" alt="LLaMA-2 architecture" width="400"/><br>
  <sub>Source: <a href="https://docs.nvidia.com/deeplearning/transformer-engine-releases/release-1.11/user-guide/examples/te_llama/tutorial_accelerate_hf_llama_with_te.html">Nvidia llama doc</a></sub>
</p>



## LLaMA 2 Model Overview
<p align="center">
  <img src="images\llama_model.png" alt="LLaMA-2 Model" width="400"/><br>
  <sub>Source: <a href="https://docs.nvidia.com/deeplearning/transformer-engine-releases/release-1.11/user-guide/examples/te_llama/tutorial_accelerate_hf_llama_with_te.html">Nvidia llama doc</a></sub>
</p>


---

## References

- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)
- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/pdf/2307.09288)

